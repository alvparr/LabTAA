# Comparación de Modelos de Machine Learning: Clasificación y Regresión

Este proyecto tiene como objetivo comparar diferentes modelos de **Machine Learning** en tareas de **clasificación** y **regresión**. En el caso de la **clasificación**, se comparan los modelos **K-Nearest Neighbors (KNN)**, **SVM (Support Vector Machine)**, **Árboles de Decisión**, **Random Forest** y **Naive Bayes**. En el caso de la **regresión**, se comparan los modelos **KNN**, **SVR**, **Árboles de Decisión** y **Random Forest**. Las métricas obtenidas incluyen **error absoluto medio (MAE)**, **error cuadrático medio (MSE)**, **raíz del error cuadrático medio (RMSE)**, **R²**, entre otras, con el fin de evaluar el desempeño de cada modelo y determinar cuál es más efectivo para cada tipo de tarea. Finalmente, se comparan el mejor modelo de clasificación con el de regresión.

## Tabla de Contenidos
1. [Introducción](#introducción)
2. [Características](#características)
3. [Requisitos Previos](#requisitos-previos)
4. [Estructura del Proyecto](#estructura-del-proyecto)
5. [Contacto](#contacto)

## Introducción

El objetivo de este proyecto es comparar diferentes modelos de Machine Learning para tareas de clasificación y regresión. Se utilizan diversos modelos para ambos tipos de tareas y se evalúan mediante métricas estándar. Los mejores modelos de cada tipo de tarea son comparados al final para observar cuál se adapta mejor a los datos en cuestión.

### Modelos de Clasificación Comparados:
- **K-Nearest Neighbors (KNN)**
- **SVM (Support Vector Machine)**
- **Árboles de Decisión**
- **Random Forest**
- **Naive Bayes**

### Modelos de Regresión Comparados:
- **K-Nearest Neighbors (KNN)**
- **SVR (Support Vector Machine)**
- **Árboles de Decisión**
- **Random Forest**


## Características

- Comparación de modelos de **clasificación** y **regresión** utilizando diferentes algoritmos.
- Evaluación con múltiples métricas como **MAE**, **MSE**, **RMSE**, **R²**, **accuracy**, **precision**, **recall**, **f1-score**, etc.
- Visualización de resultados mediante gráficos de barras.
- Uso de bibliotecas estándar como **Scikit-learn**, **Seaborn**, **Matplotlib** y **Pandas**.

## Requisitos Previos

Para ejecutar este proyecto, necesitas tener instaladas las siguientes dependencias:

- **Python 3.8+**
- **NumPy**: Para el manejo de arrays y operaciones matemáticas.
- **Pandas**: Para el manejo de datos y la creación de DataFrames.
- **Scikit-learn**: Para implementar los modelos de Machine Learning (Random Forest, KNN, SVM, Naive Bayes, etc.).
- **Matplotlib** y **Seaborn**: Para crear visualizaciones y gráficos.

Instala las dependencias necesarias usando `pip`:

```bash
pip install numpy pandas scikit-learn matplotlib seaborn
```
## Estructura del Proyecto
- Comtiene en carpetas los meodelos separados
- Un archivo para la separacion de datos
- Un archivo con todo junto para mayor facilidad de comparación llamado `Practica1_AlvaroParra.ipnb`

## Contacto

Si tienes alguna pregunta, no dudes en contactarnos:

- **Email**: [Alvaro.Parra2@alu.uclm.es](mailto:Alvaro.Parra2@alu.uclm.es)  
- **GitHub**: [alvparr](https://github.com/alvparr)